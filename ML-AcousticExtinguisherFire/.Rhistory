pop_data <- filter(flights, carrier == "UA" | carrier == "DL", arr_delay >= 0) %>%
select(carrier, arr_delay) %>%
group_by(carrier)
View(pop_data)
pop_data <- filter(flights, carrier == "UA" | carrier == "DL", arr_delay >= 0) %>%
select(carrier, arr_delay) %>%
group_by(carrier)
View(pop_data)
pop_data <- filter(flights, carrier == "UA" | carrier == "DL", arr_delay >= 0) %>%
select(carrier, arr_delay) %>%
group_by(carrier) %>%
sample_n(17000) %>%
ungroup()
amostra1 <- na.omit(pop_data) %>%
select(carrier, arr_delay) %>%
filter(carrier == "DL") %>%
mutate(sample_id = "1") %>%
sample_n(1000)
View(amostra1)
amostra2 <- na.omit(pop_data) %>%
select(carrier, arr_delay) %>%
filter(carrier == "UA") %>%
mutate(sample_id = "2") %>%
sample_n(1000)
View(amostra2)
# Exercício 3 - Crie um dataset contendo os dados das 2 amostras criadas no item anterior.
amostra <- rbind(amostra1, amostra2)
View(amostra)
# Erro padrão
erro_padrao_amostra1 = sd(amostra1$arr_delay) / sqrt(nrow(amostra1))
erro_padrao_amostra1
# Limites inferior e superior
# 1.96 é o valor de z score para 95% de confiança
lower = mean(amostra1$arr_delay) - 1.96 * erro_padrao_amostra1
upper = mean(amostra1$arr_delay) + 1.96 * erro_padrao_amostra1
lower = mean(amostra1$arr_delay) - 1.96 * erro_padrao_amostra1
# Proposta professor
ic_1 = c(lower, upper)
mean(amostra1$arr_delay)
ic_1
erro_padrao_amostra2 = sd(amostra2$arr_delay) / sqrt(nrow(amostra2))
erro_padrao_amostra2
# Proposta professor
lower = mean(amostra2$arr_delay) - 1.96 * erro_padrao_amostra2
upper = mean(amostra2$arr_delay) + 1.96 * erro_padrao_amostra2
ic_2 = c(lower, upper)
mean(amostra2$arr_delay)
ic_2
# Proposta professor
toPlot = summarise(group_by(amostra, sample_id), mean = mean(arr_delay))
View(toPlot)
toPlot = mutate(toPlot, lower = ifelse(toPlot$sample_id == 1, ic_1[1], ic_2[2]))
View(toPlot)
toPlot = mutate(toPlot, lower = ifelse(toPlot$sample_id == 1, ic_1[1], ic_2[1]))
toPlot = mutate(toPlot, upper = ifelse(toPlot$sample_id == 1, ic_1[2], ic_2[2]))
View(toPlot)
View(toPlot)
ggplot(toPlot, aes(x = sample_id, y=mean, colour = sample_id)) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width = .1)
mean_DL <- mean(amostra1$arr_delay)
mean_UA <- mean(amostra2$arr_delay)
mean_DL
mean_UA
# Cria amostras
dl <- sample_n(filter(pop_data, carrier = "DL", arr_delay > 0), 1000)
# Cria amostras
dl <- sample_n(filter(pop_data, carrier == "DL", arr_delay > 0), 1000)
ua <- sample_n(filter(pop_data, carrier == "UA", arr_delay > 0), 1000)
# Calcula erro padrão e média
se = sd(dl$arr_delay) / sqrt(nrow(dl))
mean(dl$arr_delay)
# Limites inferior e superior
lower = mean(dl$arr_delay) - 1.96 * se
upper = mean(dl$arr_delay) + 1.96 * se
ic_dl = c(lower, upper)
ic_dl
# Cria amostras
dl <- sample_n(filter(pop_data, carrier == "DL", arr_delay > 0), 1000)
ua <- sample_n(filter(pop_data, carrier == "UA", arr_delay > 0), 1000)
# Calcula erro padrão e média
se = sd(dl$arr_delay) / sqrt(nrow(dl))
mean(dl$arr_delay)
# Limites inferior e superior
lower = mean(dl$arr_delay) - 1.96 * se
upper = mean(dl$arr_delay) + 1.96 * se
ic_dl = c(lower, upper)
ic_dl
# Calcula erro padrão e média
se = sd(ua$arr_delay) / sqrt(nrow(ua))
mean(ua$arr_delay)
# Limites inferior e superior
lower = mean(ua$arr_delay) - 1.96 * se
upper = mean(ua$arr_delay) + 1.96 * se
ic_ua = c(lower, upper)
ic_ua
# Teste t
t.test(dl$arr_delay, ua$arr_delay, alternative = "greater")
# Valor p
'''
Regra
Baixo valor p: forte evidência empirica contra H0
Alto valor p: pouca ou nenhuma evidência empírica contra H0
'''
# Carrega os pacotes na sessão
library(h2o)
library(tidyverse)
library(ggbeeswarm)
# Preparação da massa de dados
# Como os dados serão gerados de forma randômica, o resultado será diferente a cada execução
dataset <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
?rnorm
produtividade = c(rnorm(1000), rnorm(1000, 0.25)
produtividade = c((rnorm(1000), rnorm(1000, 0.25))
produtividade = c(rnorm(1000), rnorm(1000, 0.25))
view(produtividade)
mean(produtividade)
# Dimensões
dim(dataset)
# Visualiza os dados
View(dataset)
# Visualiza os dados
View(dataset)
# Tipos dos dados
str(dataset)
# A variável alvo é "manutencao"
table(dataset$manutencao)
# A variável 4 é categórica
table(dataset$prioridade)
# Vamos converter a variável alvo para o tipo fator
# Isso é requerido pelo H2O
# A variável preditora categórica também será convertida
dataset <- dataset %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor)
# Tipos dos dados
str(dataset)
# Visualiza os dados
View(dataset)
# Inicializamos o H2O (Framework de Machine Learning)
# Atenção à versão do Java JDK. Instale a versão 11 a partir do link abaixo:
# https://www.oracle.com/java/technologies/downloads/
h2o.init()
version()
# Carrega os pacotes na sessão
library(h2o)
library(tidyverse)
library(ggbeeswarm)
# Preparação da massa de dados
# Como os dados serão gerados de forma randômica, o resultado será diferente a cada execução
dataset <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
?rnorm
# Dimensões
dim(dataset)
# Visualiza os dados
View(dataset)
# Tipos dos dados
str(dataset)
# A variável alvo é "manutencao"
table(dataset$manutencao)
# A variável 4 é categórica
table(dataset$prioridade)
# Vamos converter a variável alvo para o tipo fator
# Isso é requerido pelo H2O
# A variável preditora categórica também será convertida
dataset <- dataset %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor)
# Tipos dos dados
str(dataset)
# Visualiza os dados
View(dataset)
# Inicializamos o H2O (Framework de Machine Learning)
# Atenção à versão do Java JDK. Instale a versão 11 a partir do link abaixo:
# https://www.oracle.com/java/technologies/downloads/
h2o.init()
library(installr)
install.packages(intallr)
install.packages(installr)
install.packages('installr')
updateR()
library(installr)
updateR()
q()
# Carrega os pacotes na sessão
library(h2o)
# Instalação dos pacotes
install.packages("h2o")
install.packages("tidyverse")
install.packages("ggbeeswarm")
install.packages('installr')
# Carrega os pacotes na sessão
library(h2o)
library(tidyverse)
library(ggbeeswarm)
library(installr)
# Preparação da massa de dados
# Como os dados serão gerados de forma randômica, o resultado será diferente a cada execução
dataset <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
?rnorm
# Dimensões
dim(dataset)
# Visualiza os dados
View(dataset)
# Tipos dos dados
str(dataset)
# A variável alvo é "manutencao"
table(dataset$manutencao)
# A variável 4 é categórica
table(dataset$prioridade)
# Vamos converter a variável alvo para o tipo fator
# Isso é requerido pelo H2O
# A variável preditora categórica também será convertida
dataset <- dataset %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor)
# Tipos dos dados
str(dataset)
# Visualiza os dados
View(dataset)
# Inicializamos o H2O (Framework de Machine Learning)
# Atenção à versão do Java JDK. Instale a versão 11 a partir do link abaixo:
# https://www.oracle.com/java/technologies/downloads/
h2o.init()
# O H2O requer que os dados estejam no formato de dataframe do H2O
h2o_frame <- as.h2o(dataset)
# O H2O requer que os dados estejam no formato de dataframe do H2O
h2o_frame <- as.h2o(dataset)
class(h2o_frame)
head(h2o_frame)
head(h2o_frame)
# Split dos dados em treino e teste
?h2o.splitFrame
h2o_frame_split <- h2o.splitFrame(h2o_frame, ratios = 0.77)
head(h2o_frame_split)
head(h2o_frame_split)
modelo_automl <- h2o.automl(y = 'manutencao',
balance_classes = TRUE,
training_frame = h2o_frame_split[[1]],
nfolds = 4,
leaderboard_frame = h2o_frame_split[[2]],
max_runtime_secs = 60 * 2,
include_algos = c('XGBoost', 'GBM', 'GLM'),
sort_metric = "AUC")
modelo_automl <- h2o.automl(y = 'manutencao',
balance_classes = TRUE,
training_frame = h2o_frame_split[[1]],
nfolds = 4,
leaderboard_frame = h2o_frame_split[[2]],
max_runtime_secs = 60 * 2,
include_algos = c('XGBoost', 'GBM', 'GLM'),
sort_metric = "AUC")
# Extrai o leaderboard
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
View(leaderboard_automl)
# Extrai o leaderboard
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
modelo_automl <- h2o.automl(y = 'manutencao',
balance_classes = TRUE,
training_frame = h2o_frame_split[[1]],
nfolds = 4,
leaderboard_frame = h2o_frame_split[[2]],
max_runtime_secs = 60,
include_algos = c('XGBoost', 'GBM', 'GLM'),
sort_metric = "AUC")
# Extrai o leaderboard
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
View(leaderboard_automl)
# Extrai o líder (modelo com melhor performance)
lider_automl <- modelo_automl@leader
View(lider_automl)
# Para o melhor modelo extraímos a contribuição de cada variável para as previsões
# os valores extraídos são chamados de valores SHAP
# Usamos os dados de teste
?predict_contributions.H2OModel
var_contrib <- predict_contributions.H2OModel(lider_automl, h2o_frame_split[[2]])
# Primeiro preparamos um dataframe com os as métricas que precisamos
df_var_contrib <- var_contrib %>%
as.data.frame() %>%
select(-BiasTerm) %>%
gather(feature, shap_value) %>%
group_by(feature) %>%
mutate(shap_importance = mean(abs(shap_value)), shap_force = mean(shap_value)) %>%
ungroup()
View(df_var_contrib)
View(var_contrib)
# Plot da importância de cada variável para prever a variável alvo
df_var_contrib %>%
select(feature, shap_importance) %>%
distinct() %>%
ggplot(aes(x = reorder(feature, shap_importance), y = shap_importance)) +
geom_col(fill = 'blue') +
coord_flip() +
xlab(NULL) +
ylab("Valor Médio das Métricas SHAP") +
theme_minimal(base_size = 15)
# Plot de contribuição de cada variável para explicar a variável alvo
ggplot(df_var_contrib, aes(x = shap_value, y = reorder(feature, shap_importance))) +
ggbeeswarm::geom_quasirandom(groupOnX = FALSE, varwidth = TRUE, size = 0.9, alpha = 0.5, width = 0.15) +
xlab("Contribuição da Variável") +
ylab(NULL) +
theme_minimal(base_size = 15)
# Desliga o H2O
h2o.shutdown()
alfa = c(10, 20, 30)
alfa = c(10, 20, 30)
alfa + beta
alfa
beta
beta = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
alfa + beta
?matrix
?smote
?C
?C
?c
?seq
?rep
y = 6
while(y < 5){
y = y+10
print(y)
}
while(y < 5){
y = y+10
print(y)
}
?bootstrap
?dplyr
?tidyr
?tidyr
?caTools
install.packages('caTools')
caTools::sampl?abline
?abline
alturas <-c(1.75, 1.80,1.67, 1.58)
pesos <- c(80, 85, 72, 65)
alturas
pesos
abline(lm(alturas ~ pesos))
abline(lm(alturas ~ pesos))
summary(lm(alturas ~ pesos))
par(lm(alturas ~ pesos))
?par
?abline
?reta
v1 = c(2, 3, 5)
v2 = c("aa", "bb", "cc", "dd", "ee")
c(v1, v2)
bikes$dayWeek <- as.factor(weekdays(bikes$dteday))
?bike
?weekdays
?list
?rechape2
?reshape2
?grep
?unlist
y <- 1:9
y
dim(y) <- c(3,3)
dim(y)
y
class(y)
?numeric
?coerce
stardata <- as.Date("2020,2,28")
y
y[1,]
?concat
?c
?vector
?list
?vector
mtrx <- matrix(1:6, 3, 2)
mtrx[, -1]
?data.frame
# Big Data Analytics com R e Microsoft Azure Machine Learning
# Projeto 2
# Construir um modelo de Machine Learning capaz de prever,
# com base em novos dados, se a chama será extinta ou não ao usar um extintor de incêndio.
#### Configurando o repositório ####
setwd('E:/DSAFormacaoCientistaDados/BigDataAnalyticsRAzureML/Projetos-1-2/DSAProjeto02')
getwd()
#### Carregando pacotes ####
library(readxl)
library(caTools)
library(dplyr)
library(corrplot)
# install.packages("faraway")
library(faraway)
install.packages("ROCR")
library(ROCR)
library(ggplot2)
#### Carregando o dataset ####
dataset <- read_xlsx('Acoustic_Extinguisher_Fire_Dataset.xlsx')
View(dataset)
#### Analisando o dataset ####
class(dataset)
summary(dataset)
dim(dataset)
str(dataset)
colnames(dataset)
#### Tratamento dos dados ####
# Verificando dados faltantes
any(is.na(dataset))
sum(is.na(dataset))
# Criando uma coluna para identificar FUEL como Liquid Fuels ou LPG.
?transform
unique(dataset$FUEL)
dataset <- transform(dataset, TYPE = ifelse(FUEL=="lpg", "LPG", "LF"))
?relocate
dataset <- dataset %>% relocate(TYPE, .after = FUEL)
# Convertendo a coluna FUEL, SIZE, STATUS e TYPE para fator
dataset$FUEL <- as.factor(as.numeric(as.factor(dataset$FUEL)))
dataset$TYPE <- as.factor(as.numeric(as.factor(dataset$TYPE)))
dataset$SIZE <- as.factor(dataset$SIZE)
dataset$STATUS <- as.factor(dataset$STATUS)
# Verificando a distribuição da variável dependente
# Dataset está bem equilibrado em relação a distribuição da variável dependente.
prop.table(table(dataset$STATUS))
#### Criando dataset para teste e treino ####
ind <- sample.split(Y = dataset$STATUS, SplitRatio = 0.7)
train <- dataset[ind,]
test <- dataset[!ind,]
# Verificando tamanho e distribuição da variável dependente em test e train
dim(train)
dim(test)
prop.table(table(train$STATUS))
prop.table(table(test$STATUS))
# Verificando correlação entre as variáveis independentes
?corrplot
M <- cor(dataset[,4:7])
corrplot(M,mar=c(0, 0, 2, 0), type="full", order="hclust", col = COL2('RdYlBu'))
#### Criando o modelo ####
modelo <- glm(STATUS ~ ., data = train, family = binomial(link = "logit"))
summary(modelo)
#### Predição na base train ####
predictTrain <- predict(modelo, type = "response")
summary(predictTrain)
ROCRpred <- prediction(predictTrain, train$STATUS)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1, by=0.1))
exp(modelo$coefficients)
(modelo$coefficients)
#### Predição na base test ####
predn <- predict(modelo, test, type = "response")
#### Criando o modelo ####
modelo <- glm(STATUS ~ ., data = train, family = binomial(link = "logit"))
summary(modelo)
#### Predição na base test ####
pred <- predict(modelo, test, type = "response")
#### Predição na base test ####
?predict
pred <- predict(modelo, newdata = test, type = "response")
summary(pred)
ROCRpred <- prediction(pred, test$STATUS)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1, by=0.1))
perf_cost = performance(pred, "cost")
perf_cost = performance(pred, "cost")
perf_err = performance(pred, "err")
max_ind = which.max(slot(perf, "y.values")[[1]] )
perf_cost = performance(ROCRpred, "cost")
perf_err = performance(ROCRpred, "err")
perf_tpr = performance(ROCRpred, "tpr")
perf_sn_sp = performance(ROCRpred, "sens", "spec")
auc = performance(pred, measure = "auc")
auc = performance(ROCRpred, measure = "auc")
auc
print(auc@y.values)
plot(perf_cost)
plot(perf_err)
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1, by=0.1))
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1, by=0.1))
plot(ROCRperf)
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1, by=0.1))
summary(modelo)
summary(pred)
install.packages('pROC')
# install.packages('pROC')
library(pROC)
plot.roc(ROCRperf, print.auc = TRUE)
ROCRperf
ROCRpred
auc(test$STATUS, pred)
table(test$STATUS, pred >= 0.9)
table(test$STATUS, pred >= 0.2)
table(test$STATUS, pred >= 0.7)
table(test$STATUS, pred >= 0.5)
t = table(test$STATUS, pred >= 0.5)
t
t[,1]
t[1,1]
step(modelo, direction = 'both')
