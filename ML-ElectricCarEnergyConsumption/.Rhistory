erro_padrao_amostra1 = sd(amostra1$arr_delay) / sqrt(nrow(amostra1))
erro_padrao_amostra1
# Limites inferior e superior
# 1.96 é o valor de z score para 95% de confiança
lower = mean(amostra1$arr_delay) - 1.96 * erro_padrao_amostra1
upper = mean(amostra1$arr_delay) + 1.96 * erro_padrao_amostra1
lower = mean(amostra1$arr_delay) - 1.96 * erro_padrao_amostra1
# Proposta professor
ic_1 = c(lower, upper)
mean(amostra1$arr_delay)
ic_1
erro_padrao_amostra2 = sd(amostra2$arr_delay) / sqrt(nrow(amostra2))
erro_padrao_amostra2
# Proposta professor
lower = mean(amostra2$arr_delay) - 1.96 * erro_padrao_amostra2
upper = mean(amostra2$arr_delay) + 1.96 * erro_padrao_amostra2
ic_2 = c(lower, upper)
mean(amostra2$arr_delay)
ic_2
# Proposta professor
toPlot = summarise(group_by(amostra, sample_id), mean = mean(arr_delay))
View(toPlot)
toPlot = mutate(toPlot, lower = ifelse(toPlot$sample_id == 1, ic_1[1], ic_2[2]))
View(toPlot)
toPlot = mutate(toPlot, lower = ifelse(toPlot$sample_id == 1, ic_1[1], ic_2[1]))
toPlot = mutate(toPlot, upper = ifelse(toPlot$sample_id == 1, ic_1[2], ic_2[2]))
View(toPlot)
View(toPlot)
ggplot(toPlot, aes(x = sample_id, y=mean, colour = sample_id)) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width = .1)
mean_DL <- mean(amostra1$arr_delay)
mean_UA <- mean(amostra2$arr_delay)
mean_DL
mean_UA
# Cria amostras
dl <- sample_n(filter(pop_data, carrier = "DL", arr_delay > 0), 1000)
# Cria amostras
dl <- sample_n(filter(pop_data, carrier == "DL", arr_delay > 0), 1000)
ua <- sample_n(filter(pop_data, carrier == "UA", arr_delay > 0), 1000)
# Calcula erro padrão e média
se = sd(dl$arr_delay) / sqrt(nrow(dl))
mean(dl$arr_delay)
# Limites inferior e superior
lower = mean(dl$arr_delay) - 1.96 * se
upper = mean(dl$arr_delay) + 1.96 * se
ic_dl = c(lower, upper)
ic_dl
# Cria amostras
dl <- sample_n(filter(pop_data, carrier == "DL", arr_delay > 0), 1000)
ua <- sample_n(filter(pop_data, carrier == "UA", arr_delay > 0), 1000)
# Calcula erro padrão e média
se = sd(dl$arr_delay) / sqrt(nrow(dl))
mean(dl$arr_delay)
# Limites inferior e superior
lower = mean(dl$arr_delay) - 1.96 * se
upper = mean(dl$arr_delay) + 1.96 * se
ic_dl = c(lower, upper)
ic_dl
# Calcula erro padrão e média
se = sd(ua$arr_delay) / sqrt(nrow(ua))
mean(ua$arr_delay)
# Limites inferior e superior
lower = mean(ua$arr_delay) - 1.96 * se
upper = mean(ua$arr_delay) + 1.96 * se
ic_ua = c(lower, upper)
ic_ua
# Teste t
t.test(dl$arr_delay, ua$arr_delay, alternative = "greater")
# Valor p
'''
Regra
Baixo valor p: forte evidência empirica contra H0
Alto valor p: pouca ou nenhuma evidência empírica contra H0
'''
# Carrega os pacotes na sessão
library(h2o)
library(tidyverse)
library(ggbeeswarm)
# Preparação da massa de dados
# Como os dados serão gerados de forma randômica, o resultado será diferente a cada execução
dataset <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
?rnorm
produtividade = c(rnorm(1000), rnorm(1000, 0.25)
produtividade = c((rnorm(1000), rnorm(1000, 0.25))
produtividade = c(rnorm(1000), rnorm(1000, 0.25))
view(produtividade)
mean(produtividade)
# Dimensões
dim(dataset)
# Visualiza os dados
View(dataset)
# Visualiza os dados
View(dataset)
# Tipos dos dados
str(dataset)
# A variável alvo é "manutencao"
table(dataset$manutencao)
# A variável 4 é categórica
table(dataset$prioridade)
# Vamos converter a variável alvo para o tipo fator
# Isso é requerido pelo H2O
# A variável preditora categórica também será convertida
dataset <- dataset %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor)
# Tipos dos dados
str(dataset)
# Visualiza os dados
View(dataset)
# Inicializamos o H2O (Framework de Machine Learning)
# Atenção à versão do Java JDK. Instale a versão 11 a partir do link abaixo:
# https://www.oracle.com/java/technologies/downloads/
h2o.init()
version()
# Carrega os pacotes na sessão
library(h2o)
library(tidyverse)
library(ggbeeswarm)
# Preparação da massa de dados
# Como os dados serão gerados de forma randômica, o resultado será diferente a cada execução
dataset <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
?rnorm
# Dimensões
dim(dataset)
# Visualiza os dados
View(dataset)
# Tipos dos dados
str(dataset)
# A variável alvo é "manutencao"
table(dataset$manutencao)
# A variável 4 é categórica
table(dataset$prioridade)
# Vamos converter a variável alvo para o tipo fator
# Isso é requerido pelo H2O
# A variável preditora categórica também será convertida
dataset <- dataset %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor)
# Tipos dos dados
str(dataset)
# Visualiza os dados
View(dataset)
# Inicializamos o H2O (Framework de Machine Learning)
# Atenção à versão do Java JDK. Instale a versão 11 a partir do link abaixo:
# https://www.oracle.com/java/technologies/downloads/
h2o.init()
library(installr)
install.packages(intallr)
install.packages(installr)
install.packages('installr')
updateR()
library(installr)
updateR()
q()
# Carrega os pacotes na sessão
library(h2o)
# Instalação dos pacotes
install.packages("h2o")
install.packages("tidyverse")
install.packages("ggbeeswarm")
install.packages('installr')
# Carrega os pacotes na sessão
library(h2o)
library(tidyverse)
library(ggbeeswarm)
library(installr)
# Preparação da massa de dados
# Como os dados serão gerados de forma randômica, o resultado será diferente a cada execução
dataset <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
?rnorm
# Dimensões
dim(dataset)
# Visualiza os dados
View(dataset)
# Tipos dos dados
str(dataset)
# A variável alvo é "manutencao"
table(dataset$manutencao)
# A variável 4 é categórica
table(dataset$prioridade)
# Vamos converter a variável alvo para o tipo fator
# Isso é requerido pelo H2O
# A variável preditora categórica também será convertida
dataset <- dataset %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor)
# Tipos dos dados
str(dataset)
# Visualiza os dados
View(dataset)
# Inicializamos o H2O (Framework de Machine Learning)
# Atenção à versão do Java JDK. Instale a versão 11 a partir do link abaixo:
# https://www.oracle.com/java/technologies/downloads/
h2o.init()
# O H2O requer que os dados estejam no formato de dataframe do H2O
h2o_frame <- as.h2o(dataset)
# O H2O requer que os dados estejam no formato de dataframe do H2O
h2o_frame <- as.h2o(dataset)
class(h2o_frame)
head(h2o_frame)
head(h2o_frame)
# Split dos dados em treino e teste
?h2o.splitFrame
h2o_frame_split <- h2o.splitFrame(h2o_frame, ratios = 0.77)
head(h2o_frame_split)
head(h2o_frame_split)
modelo_automl <- h2o.automl(y = 'manutencao',
balance_classes = TRUE,
training_frame = h2o_frame_split[[1]],
nfolds = 4,
leaderboard_frame = h2o_frame_split[[2]],
max_runtime_secs = 60 * 2,
include_algos = c('XGBoost', 'GBM', 'GLM'),
sort_metric = "AUC")
modelo_automl <- h2o.automl(y = 'manutencao',
balance_classes = TRUE,
training_frame = h2o_frame_split[[1]],
nfolds = 4,
leaderboard_frame = h2o_frame_split[[2]],
max_runtime_secs = 60 * 2,
include_algos = c('XGBoost', 'GBM', 'GLM'),
sort_metric = "AUC")
# Extrai o leaderboard
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
View(leaderboard_automl)
# Extrai o leaderboard
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
modelo_automl <- h2o.automl(y = 'manutencao',
balance_classes = TRUE,
training_frame = h2o_frame_split[[1]],
nfolds = 4,
leaderboard_frame = h2o_frame_split[[2]],
max_runtime_secs = 60,
include_algos = c('XGBoost', 'GBM', 'GLM'),
sort_metric = "AUC")
# Extrai o leaderboard
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
View(leaderboard_automl)
# Extrai o líder (modelo com melhor performance)
lider_automl <- modelo_automl@leader
View(lider_automl)
# Para o melhor modelo extraímos a contribuição de cada variável para as previsões
# os valores extraídos são chamados de valores SHAP
# Usamos os dados de teste
?predict_contributions.H2OModel
var_contrib <- predict_contributions.H2OModel(lider_automl, h2o_frame_split[[2]])
# Primeiro preparamos um dataframe com os as métricas que precisamos
df_var_contrib <- var_contrib %>%
as.data.frame() %>%
select(-BiasTerm) %>%
gather(feature, shap_value) %>%
group_by(feature) %>%
mutate(shap_importance = mean(abs(shap_value)), shap_force = mean(shap_value)) %>%
ungroup()
View(df_var_contrib)
View(var_contrib)
# Plot da importância de cada variável para prever a variável alvo
df_var_contrib %>%
select(feature, shap_importance) %>%
distinct() %>%
ggplot(aes(x = reorder(feature, shap_importance), y = shap_importance)) +
geom_col(fill = 'blue') +
coord_flip() +
xlab(NULL) +
ylab("Valor Médio das Métricas SHAP") +
theme_minimal(base_size = 15)
# Plot de contribuição de cada variável para explicar a variável alvo
ggplot(df_var_contrib, aes(x = shap_value, y = reorder(feature, shap_importance))) +
ggbeeswarm::geom_quasirandom(groupOnX = FALSE, varwidth = TRUE, size = 0.9, alpha = 0.5, width = 0.15) +
xlab("Contribuição da Variável") +
ylab(NULL) +
theme_minimal(base_size = 15)
# Desliga o H2O
h2o.shutdown()
alfa = c(10, 20, 30)
alfa = c(10, 20, 30)
alfa + beta
alfa
beta
beta = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
alfa + beta
?matrix
?smote
?C
?C
?c
?seq
?rep
y = 6
while(y < 5){
y = y+10
print(y)
}
while(y < 5){
y = y+10
print(y)
}
?bootstrap
?dplyr
?tidyr
?tidyr
?caTools
install.packages('caTools')
caTools::sampl?abline
?abline
alturas <-c(1.75, 1.80,1.67, 1.58)
pesos <- c(80, 85, 72, 65)
alturas
pesos
abline(lm(alturas ~ pesos))
abline(lm(alturas ~ pesos))
summary(lm(alturas ~ pesos))
par(lm(alturas ~ pesos))
?par
?abline
?reta
v1 = c(2, 3, 5)
v2 = c("aa", "bb", "cc", "dd", "ee")
c(v1, v2)
bikes$dayWeek <- as.factor(weekdays(bikes$dteday))
?bike
?weekdays
?list
?rechape2
?reshape2
?grep
?unlist
y <- 1:9
y
dim(y) <- c(3,3)
dim(y)
y
class(y)
?numeric
?coerce
stardata <- as.Date("2020,2,28")
y
y[1,]
?concat
?c
?vector
?list
?vector
mtrx <- matrix(1:6, 3, 2)
mtrx[, -1]
?data.frame
setwd('E:/DSAFormacaoCientistaDados/BigDataAnalyticsRAzureML/Projetos-1-2/Projeto01')
getwd()
library(dplyr)
library(ggplot2)
library(mlbench)
library(caret)
library(randomForest)
library(janitor)
library(e1071)
library(car)
library(lmtest)
library(readxl)
dataset <- read_xlsx('FEV-data-Excel.xlsx')
#### Adicionando coluna de index e realocando em primeiro ####
dataset$index <- 1:nrow(dataset)
?relocate
dataset <- dataset %>% relocate(index, .before = 1 )
#### Limpando os nomes das colunas para evitar problemas ####
?clean_names
dataset <- clean_names(dataset, "lower_camel")
#### Identificando os dados faltantes ####
any(is.na(dataset))
sum(is.na(dataset))
# Adicionando coluna com a contagem de NA's por registro
dataset$countNA <- rowSums(is.na(dataset))
View(dataset)
# 11 carros possuem dados NA's
View(dataset %>% filter(countNA > 0))
# 9 carros com o dado de mean - Energy consumption [kWh/100 km] faltando
View(dataset %>% filter(is.na(meanEnergyConsumptionKWh100Km)))
# 9 carros com variável target mean - Energy consumption [kWh/100 km] faltando
View(dataset %>% filter(is.na(meanEnergyConsumptionKWh100Km)))
# (index 10) Citroen e-C4 *** Vehicle Consumption 170 Wh/km *** (https://ev-database.org/car/1587/Citroen-e-C4)
dataset[10,"meanEnergyConsumptionKWh100Km"] = (170/1000) * 100 # conversão Wh/km > kWh e para 100km
# (index 30) Peugeot e-2008 *** Vehicle Consumption	184 Wh/km *** (https://ev-database.org/car/1206/Peugeot-e-2008-SUV)
dataset[30,"meanEnergyConsumptionKWh100Km"] = (184/1000) * 100 # conversão Wh/km > kWh e para 100km
dataset[30,24] = 8.5 # Acceleration 0-100 kph [s]
dataset[30,18] = 482 # Maximum load capacity [kg]
dataset[30,"permissableGrossWeightKg"] = 2030 # GVWH
# (index 40) Tesla Model 3 Standard Range Plus *** Vehicle Consumption	146 Wh/km *** (https://ev-database.org/car/1485/Tesla-Model-3-Standard-Range-Plus)
dataset[40,"meanEnergyConsumptionKWh100Km"] = (146/1000) * 100 # conversão Wh/km > kWh e para 100km
dataset[40,18] = 389 # Maximum load capacity [kg]
dataset[40,"permissableGrossWeightKg"] = 2014 # GVWH
# (index 41) Tesla Model 3 Long Range *** Vehicle Consumption	154 Wh/km *** (https://ev-database.org/car/1321/Tesla-Model-3-Long-Range-Dual-Motor)
dataset[41,"meanEnergyConsumptionKWh100Km"] = (154/1000) * 100 # conversão Wh/km > kWh e para 100km
dataset[41,18] = 388 # Maximum load capacity [kg]
dataset[41,"permissableGrossWeightKg"] = 2232 # GVWH
# (index 42) Tesla Model 3 Performance *** Vehicle Consumption	162 Wh/km *** (https://ev-database.org/car/1322/Tesla-Model-3-Performance)
dataset[42,"meanEnergyConsumptionKWh100Km"] = (162/1000) * 100 # conversão Wh/km > kWh e para 100km
dataset[42,18] = 388 # Maximum load capacity [kg]
dataset[42,"permissableGrossWeightKg"] = 2232 # GVWH
# (index 43) Tesla Model S Long Range Plus *** Vehicle Consumption 178 Wh/km *** (https://ev-database.org/car/1323/Tesla-Model-S-Long-Range-Plus)
dataset[43,"meanEnergyConsumptionKWh100Km"] = (178/1000) * 100 # conversão Wh/km > kWh e para 100km
dataset[43,"maximumLoadCapacityKg"] = 744 # https://www.evspecifications.com/en/model/3 # Trunk volume
dataset[43,"permissableGrossWeightKg"] = 2694 # https://www.evspecifications.com/en/model/3 # GVWH
# (index 44) Tesla Model S Performance *** Vehicle Consumption *	183 Wh/km *** (https://ev-database.org/car/1324/Tesla-Model-S-Performance)
dataset[44,"meanEnergyConsumptionKWh100Km"] = (183/1000) * 100 # conversão Wh/km > kWh e para 100km
dataset[44,"maximumLoadCapacityKg"] = 744 # https://www.evspecifications.com/en/model/3 # Trunk volume
dataset[44,"permissableGrossWeightKg"] = 2720 # https://www.evspecifications.com/en/model/3 # GVWH
# (index 45) Tesla Model X Long Range Plus *** Vehicle Consumption 204 Wh/km *** (https://ev-database.org/car/1325/Tesla-Model-X-Long-Range-Plus)
dataset[45,"meanEnergyConsumptionKWh100Km"] = (204/1000) * 100 # conversão Wh/km > kWh e para 100km
dataset[45,"maximumLoadCapacityKg"] = 357 # https://www.evspecifications.com/en/ # Trunk volume
dataset[45,"permissableGrossWeightKg"] = 3079 # https://www.evspecifications.com/en/model/3 # GVWH
# (index 46) Tesla Model X Performance *** Vehicle Consumption	221 Wh/km *** (https://ev-database.org/car/1208/Tesla-Model-X-Performance)
dataset[46,"meanEnergyConsumptionKWh100Km"] = (221/1000) * 100 # conversão Wh/km > kWh e para 100km
dataset[46,"maximumLoadCapacityKg"] = 357 # https://www.evspecifications.com/en/ # Trunk volume
dataset[46,"permissableGrossWeightKg"] = 3120 # https://www.evspecifications.com/en/model/3 # GVWH
# (index 52) Mercedes-Benz EQV (https://ev-database.org/car/1240/Mercedes-EQV-300-Long)
dataset[52,24] = 12.1 #Acceleration 0-100 kph [s]
dataset[52,"typeOfBrakes"] = "disc (front + rear)" # https://www.evspecifications.com/en/model/0a98172
dataset[52,"bootCapacityVdaL"] = mean(dataset$`bootCapacityVdaL`, na.rm = T) # Informação não encontrada, utilizado a média da coluna
# (index 53) Nissan e-NV200 evalia (https://ev-database.org/car/1117/Nissan-e-NV200-Evalia)
dataset[53,24] = 14 #Acceleration 0-100 kph [s]
# Verificando novamente valores nulos
any(is.na(dataset))
sum(is.na(dataset))
#### Convertendo as colunas chr em numérico ####
dataset$`typeOfBrakes` <- as.numeric(as.factor(dataset$`typeOfBrakes`))
dataset$`driveType` <- as.numeric(as.factor(dataset$`driveType`))
View(dataset)
# Analisando o dataset após tratamento dos valores nulos
class(dataset)
summary(dataset)
str(dataset)
dim(dataset)
colnames(dataset)
View(dataset)
# Salvando o dataset tratado como csv para uso no Azure
write.csv(dataset, "dataset_final.csv", row.names = FALSE)
#### Analisando os dados graficamente ####
colNames <- colnames(dataset[,5:26])
colNames
histVar <- function(df, variables) {
for (variable in variables) {
hist(df[[variable]], main = paste("Histograma de" , variable))
}
}
histVar(dataset, colNames)
boxPlotGraf <- function(df, variables) {
for (variable in variables) {
boxplot(df[[variable]], main = paste("Boxplot de" , variable))
}
}
boxPlotGraf(dataset, colNames)
#### Criando o modelo de regressão linear múltipla ####
# Como o dataset possui apenas 53 registros não optei por separar entre treino e teste
# mas sim treinar o modelo com o dataset todo e avaliar as medidas do modelo
datasetReg <- dataset[,5:26] # Criando o dataset somente com as variáveis necessárias
str(datasetReg)
class(datasetReg)
dim(datasetReg)
View(datasetReg)
modeloLM <- lm(meanEnergyConsumptionKWh100Km ~ ., data = datasetReg) # Criando o modelo
summary(modeloLM)
#### Analisando correlação entre as variáveis independentes ####
cor(datasetReg[,1:21])
#### Utilizando o algoritmo stepwise para melhor ajuste e seleção das variáveis ####
step(modeloLM, direction = "both", scale = 0.962^2)
modeloLM2 <- lm(formula = meanEnergyConsumptionKWh100Km ~ enginePowerKm +
driveType + batteryCapacityKWh + rangeWltpKm + lengthCm +
heightCm + minimalEmptyWeightKg + maximumLoadCapacityKg +
numberOfDoors + tireSizeIn + maximumSpeedKph + maximumDcChargingPowerKW,
data = datasetReg)
summary(modeloLM2)
modeloLM2$coefficients
#### Avaliando o modelo ####
par(mfrow = c(2,2))
plot(modeloLM2, which = c(1:4), pch = 20)
?outlierTest
outlierTest(modeloLM2)
shapiro.test(modeloLM2$residuals)
durbinWatsonTest(modeloLM2)
?bptest
?ncvTest
ncvTest(lm(meanEnergyConsumptionKWh100Km ~ enginePowerKm +
driveType + batteryCapacityKWh + rangeWltpKm + lengthCm +
heightCm + minimalEmptyWeightKg + maximumLoadCapacityKg +
numberOfDoors + tireSizeIn + maximumSpeedKph + maximumDcChargingPowerKW, data = datasetReg))
summary(modeloLM)
summary(modeloLM2)
# Modelo final:
summary(modeloLM2)
modeloLM2$coefficients
# Modelo final:
summary(modeloLM2)
modeloLM2$coefficients
# R2 0,9523, ou seja, 95,23% da variação dos scores médios do consumo de energia
